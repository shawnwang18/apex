rm rank_logging/*
rm logs/*
nsys profile -w true --trace cuda,nvtx,osrt -o logs/export_nsys_toy_2gpu \
python -m torch.distributed.launch \
--nproc_per_node=2 toy.py  \
--batch-size 8192 \
--input-size 8192 \
--hidden-size 8192 \
--output-size 8192 \
--hidden-layers 5 \
--iteration-number 10 \
--warmup-number 0  \
--layers-per-bucket 1 \
--debug-apex \
--logging  \
--logdir /home/scratch.shawnw_gpu/docker/apex/examples/toy/rank_logging
#QdstrmImporte logs/export_nsys_toy.qdstrm

